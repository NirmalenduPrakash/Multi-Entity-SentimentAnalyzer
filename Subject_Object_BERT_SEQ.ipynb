{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Subject-Object-BERT-SEQ.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f5086ae8d3304e24b9115d21b05c5cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6469bb161a88435c9a6f432d1e37f5ad",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_10bf6f8ca2554f0497b3d9ea238633e8",
              "IPY_MODEL_d753256805f74734832b9db8b754cbdf"
            ]
          }
        },
        "6469bb161a88435c9a6f432d1e37f5ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10bf6f8ca2554f0497b3d9ea238633e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6a956f0df456493e9176779c568bfc8a",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e7544570355042cfbcc79a77370336a0"
          }
        },
        "d753256805f74734832b9db8b754cbdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c615ac542ee34d5db04582e0aee60f86",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 361/361 [00:00&lt;00:00, 13.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc2ec7f037c84482b16eb17c820f1db6"
          }
        },
        "6a956f0df456493e9176779c568bfc8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e7544570355042cfbcc79a77370336a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c615ac542ee34d5db04582e0aee60f86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc2ec7f037c84482b16eb17c820f1db6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d0ba854fbae941aebf21b0cb278355bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_608a495f83324c0ea6793bc5a9680b96",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_11f139f42fdb44b78e4dc7f52608302b",
              "IPY_MODEL_3389d8e909334c19911f340e7e993c01"
            ]
          }
        },
        "608a495f83324c0ea6793bc5a9680b96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11f139f42fdb44b78e4dc7f52608302b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_63fef510986744818b790965e424e76b",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dc7380abc7254562a5496dc16a9d8fc8"
          }
        },
        "3389d8e909334c19911f340e7e993c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_737c2ea05524457c9d105d3738fe9724",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 440M/440M [00:12&lt;00:00, 36.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_13dda41be3e94f638281ed80eed39d5d"
          }
        },
        "63fef510986744818b790965e424e76b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dc7380abc7254562a5496dc16a9d8fc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "737c2ea05524457c9d105d3738fe9724": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "13dda41be3e94f638281ed80eed39d5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkgENdIIrjs3",
        "colab_type": "code",
        "outputId": "4e887777-6677-40ed-a373-7912467f9a4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7Jels3nr6ek",
        "colab_type": "code",
        "outputId": "37ec15e0-f26d-4049-f8ad-f62a26119f63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        }
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "!pip install transformers\n",
        "from transformers import BertTokenizer\n",
        "# from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.nn import functional as F"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 501kB 12.4MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.0MB 44.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870kB 38.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.7MB 58.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=e936679c9b85b325635c04e704dc9ca2b304fb25a728ce6db3e97f40e55d19ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbtfGyyDsBo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open('/content/drive/My Drive/data.pkl','rb') as f:\n",
        "  df=pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxBmBLQwSTpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhPwMituNhlm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH=len(df.iloc[0]['encoding'])\n",
        "tag_index={'[PAD]':0,'<s>':1,'B-AG':2,'I-AG':3,'B-TG':4,'I-TG':5,'O':6,'</s>':7}\n",
        "df['labels']=df['labels'].apply(lambda x: [tag_index[lbl] for lbl in x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiefdIZVtE-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "class SequenceDataset(Dataset):\n",
        "  def __init__(self,df):\n",
        "    self.df=df\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return torch.tensor(self.df.iloc[index]['encoding']),torch.tensor(self.df.iloc[index]['attn_mask']),torch.tensor(self.df.iloc[index]['labels'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRmU_nsgJuuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "msk = np.random.rand(len(df)) < 0.8\n",
        "train=df[msk]\n",
        "val=df[~msk]\n",
        "train_set=SequenceDataset(train)\n",
        "val_set=SequenceDataset(val)\n",
        "train_loader=DataLoader(train_set, batch_size = 16)\n",
        "val_loader = DataLoader(val_set, batch_size = 16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYIsNn8sJ45L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, freeze_bert = True):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        for p in self.bert_layer.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "    def forward(self, seq, attn_masks):\n",
        "        cont_reps, _ = self.bert_layer(seq, attention_mask = attn_masks)\n",
        "        return cont_reps[:,0]        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqgknxMKZmhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self,vocab_size, hidden_size,output_size, dropout_p=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.vocab_size=vocab_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.embedding = nn.Embedding(self.vocab_size,self.hidden_size)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size,batch_first=True)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, hidden,input):\n",
        "       embedded = self.embedding(input).view(hidden.shape[0], 1, -1)\n",
        "       embedded = self.dropout(embedded)\n",
        "       output, hidden = self.gru(embedded, hidden.permute(1,0,2).contiguous())\n",
        "       output = F.log_softmax(self.out(output), dim=2)\n",
        "       return output, hidden.permute(1,0,2)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVjG7-4LKu-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self,vocab_size, hidden_size,output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.vocab_size=vocab_size\n",
        "        # self.embedding_size=embedding_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.vocab_size,self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size,batch_first=True)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        # print(input.shape,hidden.shape,encoder_outputs.shape)\n",
        "        embedded = self.embedding(input).view(encoder_outputs.shape[0], 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "        \n",
        "        hidden=hidden.expand(encoder_outputs.shape[0],1,-1)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded, hidden), 2)), dim=2)\n",
        "        # print(attn_weights.shape,encoder_outputs.shape)\n",
        "        # attn_applied=attn_weights.permute(0,2,1)*encoder_outputs\n",
        "        attn_applied = torch.bmm(attn_weights,\n",
        "                                 encoder_outputs)\n",
        "\n",
        "        output = torch.cat((embedded, attn_applied),dim=2)\n",
        "        output = self.attn_combine(output)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden.permute(1,0,2).contiguous())\n",
        "        output = F.log_softmax(self.out(output), dim=2)\n",
        "        return output, hidden.permute(1,0,2), attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPIM4StnMPK0",
        "colab_type": "code",
        "outputId": "4e47ae5a-2adb-49a6-cdf2-15264ac770b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f5086ae8d3304e24b9115d21b05c5cfe",
            "6469bb161a88435c9a6f432d1e37f5ad",
            "10bf6f8ca2554f0497b3d9ea238633e8",
            "d753256805f74734832b9db8b754cbdf",
            "6a956f0df456493e9176779c568bfc8a",
            "e7544570355042cfbcc79a77370336a0",
            "c615ac542ee34d5db04582e0aee60f86",
            "fc2ec7f037c84482b16eb17c820f1db6",
            "d0ba854fbae941aebf21b0cb278355bc",
            "608a495f83324c0ea6793bc5a9680b96",
            "11f139f42fdb44b78e4dc7f52608302b",
            "3389d8e909334c19911f340e7e993c01",
            "63fef510986744818b790965e424e76b",
            "dc7380abc7254562a5496dc16a9d8fc8",
            "737c2ea05524457c9d105d3738fe9724",
            "13dda41be3e94f638281ed80eed39d5d"
          ]
        }
      },
      "source": [
        "import torch.optim as optim\n",
        "import tqdm\n",
        "import os\n",
        "import pickle\n",
        "# embedding_size=100\n",
        "hidden_size=768\n",
        "# bert_model=BertModel.from_pretrained('bert-base-uncased')\n",
        "vocab_size=len(tag_index)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "encoder=Encoder().to(device)\n",
        "\n",
        "if(os.path.exists('/content/drive/My Drive/BERT-SEQ-Tagger/encoder.pt')):\n",
        "    encoder.load_state_dict(torch.load('/content/drive/My Drive/BERT-SEQ-Tagger/encoder.pt'))\n",
        "\n",
        "decoder=Decoder(vocab_size,hidden_size,len(tag_index)).to(device)\n",
        "if(os.path.exists('/content/drive/My Drive/BERT-SEQ-Tagger/decoder.pt')):\n",
        "    decoder.load_state_dict(torch.load('/content/drive/My Drive/BERT-SEQ-Tagger/decoder.pt'))\n",
        "\n",
        "criterion = nn.NLLLoss(ignore_index=tag_index['[PAD]'])\n",
        "# enc_optimizer = optim.Adam(encoder.parameters(), lr = 2e-5)\n",
        "dec_optimizer = optim.Adam(decoder.parameters(), lr = 1e-5)\n",
        "\n",
        "# training_loss=[]\n",
        "val_losses=[]\n",
        "if(os.path.exists('/content/drive/My Drive/BERT-SEQ-Tagger/val_losses.pkl')):\n",
        "  with open('/content/drive/My Drive/BERT-SEQ-Tagger/val_losses.pkl','rb') as f:\n",
        "    val_losses=pickle.load(f)\n",
        "\n",
        "for _e in range(200):\n",
        "    train_loss=0\n",
        "    for t, (seq, attn_mask, labels) in enumerate(train_loader):\n",
        "        # data_batch = sort_batch_by_len(data_dict)\n",
        "        batch_size=seq.shape[0]\n",
        "        seq=seq.to(device)\n",
        "        attn_mask=attn_mask.to(device)\n",
        "        labels =labels.to(device) #torch.tensor(data_batch).to(device)\n",
        "                \n",
        "        # enc_optimizer.zero_grad()\n",
        "        dec_optimizer.zero_grad()\n",
        "        encoder_output=encoder(seq,attn_mask)        \n",
        "        decoder_input = torch.tensor([batch_size*[tag_index['<s>']]], device=device).view(-1,1)\n",
        "        decoder_hidden=encoder_output.view(batch_size,1,-1)\n",
        "        labels= torch.cat((labels,torch.tensor(batch_size*[tag_index['</s>']], device=device).view(-1,1)),dim=1)\n",
        "        loss=0\n",
        "        for di in range(labels.shape[1]):\n",
        "          decoder_output,decoder_hidden=decoder(decoder_hidden,decoder_input)\n",
        "          # print(decoder_output.squeeze(0).shape)\n",
        "          loss += criterion(decoder_output.view(encoder_output.shape[0],-1), labels[:,di])\n",
        "          train_loss+=loss.data.item()\n",
        "          decoder_input = labels[:,di]\n",
        "        loss.backward()   \n",
        "        # enc_optimizer.step()\n",
        "        dec_optimizer.step()\n",
        "    train_loss=train_loss/len(train)\n",
        "    # print(train_loss)    \n",
        "    val_loss=0\n",
        "    for t, (seq, attn_mask, labels) in enumerate(val_loader):\n",
        "        seq=seq.to(device)\n",
        "        attn_mask=attn_mask.to(device)\n",
        "        labels =labels.to(device) #torch.tensor(data_batch).to(device)\n",
        "        batch_size=seq.shape[0]\n",
        "        # enc_optimizer.zero_grad()\n",
        "        dec_optimizer.zero_grad()\n",
        "        encoder_output=encoder(seq,attn_mask)\n",
        "        decoder_input = torch.tensor([batch_size*[tag_index['<s>']]], device=device).view(-1,1)\n",
        "        decoder_hidden=encoder_output.view(batch_size,1,-1)\n",
        "        labels= torch.cat((labels,torch.tensor(batch_size*[tag_index['</s>']], device=device).view(-1,1)),dim=1)\n",
        "        loss=0\n",
        "        for di in range(labels.shape[1]):\n",
        "          decoder_output,decoder_hidden=decoder(decoder_hidden,decoder_input)\n",
        "          # print(decoder_output.squeeze(0).shape)\n",
        "          loss += criterion(decoder_output.view(encoder_output.shape[0],-1), labels[:,di])\n",
        "          decoder_input = labels[:,di]\n",
        "          # _, top_idx = decoder_output.data.topk(1)\n",
        "          # decoder_input = top_idx.view(-1)\n",
        "          val_loss+=loss.data.item()\n",
        "    val_loss=val_loss/len(val)\n",
        "    if(len(val_losses)>0 and val_loss<min(val_losses)):\n",
        "      torch.save(encoder.state_dict(), '/content/drive/My Drive/BERT-SEQ-Tagger/encoder.pt') \n",
        "      torch.save(decoder.state_dict(), '/content/drive/My Drive/BERT-SEQ-Tagger/decoder.pt')  \n",
        "    val_losses.append(val_loss)      \n",
        "    print('training loss:{} validation loss:{}'.format(train_loss,val_loss))       "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5086ae8d3304e24b9115d21b05c5cfe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0ba854fbae941aebf21b0cb278355bc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "training loss:39.35991589239764 validation loss:43.826463055253406\n",
            "training loss:39.331333402254394 validation loss:43.890565284560154\n",
            "training loss:39.36235692006367 validation loss:43.89929524733911\n",
            "training loss:39.31968021992948 validation loss:43.91838281839052\n",
            "training loss:39.271852087648185 validation loss:43.814784980863806\n",
            "training loss:39.271614001349946 validation loss:43.899170158460315\n",
            "training loss:39.24298890185159 validation loss:43.95398934998723\n",
            "training loss:39.2680966125463 validation loss:43.94822983885601\n",
            "training loss:39.230188481294974 validation loss:43.90578533481066\n",
            "training loss:39.185819162640946 validation loss:43.94691698201447\n",
            "training loss:39.15019943164688 validation loss:43.8743080613835\n",
            "training loss:39.1979382640497 validation loss:43.86892881180962\n",
            "training loss:39.21436924076175 validation loss:44.00979377068462\n",
            "training loss:39.164274306146574 validation loss:43.99739631310058\n",
            "training loss:39.14845025125 validation loss:44.01422585664488\n",
            "training loss:39.17613495788631 validation loss:43.9284725775384\n",
            "training loss:39.14578448313286 validation loss:43.89531148984229\n",
            "training loss:39.11823788126367 validation loss:43.887346151193796\n",
            "training loss:39.05329798250016 validation loss:43.976163546910236\n",
            "training loss:39.13289465173349 validation loss:43.96664457373345\n",
            "training loss:39.12201480024228 validation loss:44.06015688737954\n",
            "training loss:39.07525675047071 validation loss:44.11639894780112\n",
            "training loss:39.10403190744284 validation loss:44.09090900418792\n",
            "training loss:39.06804642335697 validation loss:44.168564526816645\n",
            "training loss:39.05795565953945 validation loss:44.004243075753614\n",
            "training loss:39.07640203636043 validation loss:44.16135336773629\n",
            "training loss:39.07456070147133 validation loss:44.09610770955353\n",
            "training loss:39.05225995952741 validation loss:43.979070609441315\n",
            "training loss:39.040846016955825 validation loss:44.17852544993726\n",
            "training loss:38.99162494108854 validation loss:44.08422027723364\n",
            "training loss:39.031143263991524 validation loss:44.08822423135069\n",
            "training loss:39.07563965605513 validation loss:44.000527327298556\n",
            "training loss:38.98071541607122 validation loss:44.11654124256188\n",
            "training loss:38.970571062074015 validation loss:44.21286174356467\n",
            "training loss:39.00262573059723 validation loss:44.047729395564986\n",
            "training loss:39.003610628750984 validation loss:44.15018085195251\n",
            "training loss:38.97279949206054 validation loss:44.090875607841774\n",
            "training loss:38.958252248539445 validation loss:44.23469485135673\n",
            "training loss:38.95186877823958 validation loss:44.14665726252629\n",
            "training loss:38.96342659300402 validation loss:44.125096910242405\n",
            "training loss:38.898460473135245 validation loss:44.2010360625029\n",
            "training loss:38.92893281617666 validation loss:44.11989917768289\n",
            "training loss:38.93048249943026 validation loss:44.11219807693071\n",
            "training loss:38.87242603540334 validation loss:44.256963785796515\n",
            "training loss:38.91936467593316 validation loss:44.19020337867624\n",
            "training loss:38.90572675583771 validation loss:44.31383979856404\n",
            "training loss:38.89936924151411 validation loss:44.17570222970627\n",
            "training loss:38.846674499469636 validation loss:44.227340807156985\n",
            "training loss:38.911171816965776 validation loss:44.24317202317508\n",
            "training loss:38.90591314957834 validation loss:44.216814494871\n",
            "training loss:38.86167344169675 validation loss:44.129512415393854\n",
            "training loss:38.79887640882036 validation loss:44.230465521031185\n",
            "training loss:38.87429633592752 validation loss:44.379926919631586\n",
            "training loss:38.877367698375444 validation loss:44.355710205666085\n",
            "training loss:38.78356307872735 validation loss:44.29793971029554\n",
            "training loss:38.82203759556845 validation loss:44.2415873852532\n",
            "training loss:38.81759111921408 validation loss:44.28370511447218\n",
            "training loss:38.78772213314298 validation loss:44.39433219203907\n",
            "training loss:38.80679325423383 validation loss:44.28763724435767\n",
            "training loss:38.793650653857405 validation loss:44.2154262449228\n",
            "training loss:38.765108201373636 validation loss:44.312320914671815\n",
            "training loss:38.78858693915631 validation loss:44.364281906196936\n",
            "training loss:38.75990461659019 validation loss:44.41300281792973\n",
            "training loss:38.76235484249181 validation loss:44.33825239120786\n",
            "training loss:38.73871333564307 validation loss:44.33441524311007\n",
            "training loss:38.75833398423638 validation loss:44.38599252150826\n",
            "training loss:38.7308551148439 validation loss:44.489087689562176\n",
            "training loss:38.70007557613018 validation loss:44.4957619913698\n",
            "training loss:38.72148319848032 validation loss:44.55140509928815\n",
            "training loss:38.74948297210188 validation loss:44.57591239210183\n",
            "training loss:38.67002825133009 validation loss:44.57510883029703\n",
            "training loss:38.614534947366295 validation loss:44.476523254242984\n",
            "training loss:38.67165787519098 validation loss:44.7590897942097\n",
            "training loss:38.650426589661095 validation loss:44.526944055565714\n",
            "training loss:38.62070488344653 validation loss:44.58167322934238\n",
            "training loss:38.56904316182525 validation loss:44.51716192767071\n",
            "training loss:38.63890492058324 validation loss:44.614019268177664\n",
            "training loss:38.5971219135443 validation loss:44.87675869535384\n",
            "training loss:38.498051145696415 validation loss:44.62383641462409\n",
            "training loss:38.612081750744274 validation loss:44.753010296953214\n",
            "training loss:38.60393781676588 validation loss:44.61036810502175\n",
            "training loss:38.50015548003639 validation loss:44.75360233752697\n",
            "training loss:38.565595595031894 validation loss:44.599421084279705\n",
            "training loss:38.54806084548706 validation loss:44.868119083344936\n",
            "training loss:38.54723669654054 validation loss:44.8471938686839\n",
            "training loss:38.576728452576766 validation loss:44.76134254663525\n",
            "training loss:38.49397063458215 validation loss:44.8898437748243\n",
            "training loss:38.46021288238273 validation loss:44.78413593566944\n",
            "training loss:38.449379014361234 validation loss:44.85805469196678\n",
            "training loss:38.373118588792146 validation loss:45.02667476121653\n",
            "training loss:38.49003701212599 validation loss:45.1786098186667\n",
            "training loss:38.489415874613464 validation loss:44.93698846797932\n",
            "training loss:38.448983141900136 validation loss:44.866620828253616\n",
            "training loss:38.449898012841295 validation loss:44.97420356182928\n",
            "training loss:38.451915761622296 validation loss:44.98319371054037\n",
            "training loss:38.45139984922854 validation loss:45.01885595645062\n",
            "training loss:38.439383794717294 validation loss:45.07953084403596\n",
            "training loss:38.42103794238581 validation loss:45.20928873194599\n",
            "training loss:38.40519316050007 validation loss:45.2245596250055\n",
            "training loss:38.3323354892948 validation loss:45.22473345292668\n",
            "training loss:38.32517113283234 validation loss:45.136867554170855\n",
            "training loss:38.332668898761355 validation loss:45.607966535663\n",
            "training loss:38.380403288717915 validation loss:45.21162511850193\n",
            "training loss:38.357134085857126 validation loss:45.219799370020155\n",
            "training loss:38.37213917355716 validation loss:45.29236518532884\n",
            "training loss:38.358143643231834 validation loss:45.532902677305486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ72t0kNfeDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open('/content/drive/My Drive/BERT-SEQ-Tagger/val_losses.pkl','wb') as f:\n",
        "  pickle.dump(val_losses,f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geV5BvS4U6IO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder=Encoder().to(device)\n",
        "encoder.load_state_dict(torch.load('/content/drive/My Drive/BERT-SEQ-Tagger/encoder.pt'))\n",
        "decoder=AttnDecoderRNN(vocab_size,hidden_size,len(tag_index)).to(device)\n",
        "decoder.load_state_dict(torch.load('/content/drive/My Drive/BERT-SEQ-Tagger/decoder.pt'))\n",
        "seq=torch.tensor(val.iloc[0]['encoding']).view(1,-1).to(device)\n",
        "attn_mask=torch.tensor(val.iloc[0]['attn_mask']).view(1,-1).to(device)\n",
        "labels=torch.tensor(val.iloc[0]['labels']).view(1,-1).to(device)\n",
        "\n",
        "encoder_output=encoder(seq,attn_mask)\n",
        "decoder_input = torch.tensor([encoder_output.shape[0]*[tag_index['<s>']]], device=device).view(-1,1)\n",
        "decoder_hidden=decoder.initHidden()\n",
        "\n",
        "labels= torch.cat((labels,torch.tensor([encoder_output.shape[0]*[tag_index['<s>']]], device=device).view(-1,1)),dim=1)\n",
        "loss=0\n",
        "for di in range(labels.shape[1]):\n",
        "  decoder_output,decoder_hidden,_=decoder(decoder_input,decoder_hidden,encoder_output)\n",
        "  # print(decoder_output.squeeze(0).shape)\n",
        "  # loss += criterion(decoder_output.view(encoder_output.shape[0],-1), labels[:,di])\n",
        "  _, top_idx = decoder_output.data.topk(1)\n",
        "  decoder_input = top_idx.view(-1)\n",
        "  print(decoder_input)        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6HyVjQNfaFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}